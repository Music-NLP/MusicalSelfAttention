{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "Music_NLP_Self_Attention.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a2ff3ef3a12340feb060fd2e535d150c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fe02979831c849148167a39c8ca5df03",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a9b9a0c46d5842bbae3bc30f2eddf1bb",
              "IPY_MODEL_01aedd15071a4af49c0bb3813c24dc7c",
              "IPY_MODEL_862324f1b1b84901973ffef866faabc8"
            ]
          }
        },
        "fe02979831c849148167a39c8ca5df03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a9b9a0c46d5842bbae3bc30f2eddf1bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3e1817a32a22467e8a50b7ccfb9bb7c6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ef04b5edb2584b81858e32a292203dda"
          }
        },
        "01aedd15071a4af49c0bb3813c24dc7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_71a8fe9c180e4d0f9c31f9eff8b77da3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 100,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 100,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1097bfdedc1148358a9f0d800f9376b4"
          }
        },
        "862324f1b1b84901973ffef866faabc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_69498d87934d49a9864dfbee2f00d385",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 100/100 [01:53&lt;00:00,  1.22it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b45ca13467cb410a8c80e0e693614a99"
          }
        },
        "3e1817a32a22467e8a50b7ccfb9bb7c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ef04b5edb2584b81858e32a292203dda": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "71a8fe9c180e4d0f9c31f9eff8b77da3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1097bfdedc1148358a9f0d800f9376b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "69498d87934d49a9864dfbee2f00d385": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b45ca13467cb410a8c80e0e693614a99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0e663659e57242aa8bea479addd72171": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_66d94737180d4b60939a5b5e47eee177",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5379065c672f49fdbb0c3ebb76ab69fc",
              "IPY_MODEL_93b5202556554c8f88c2d3852df634f0",
              "IPY_MODEL_fe9e2d8094e9467eaf79f186e18eb207"
            ]
          }
        },
        "66d94737180d4b60939a5b5e47eee177": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5379065c672f49fdbb0c3ebb76ab69fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1a9e930b35654998a83d1bba6b319f44",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e36e409e43f14b28ab702d6d8db6fac0"
          }
        },
        "93b5202556554c8f88c2d3852df634f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_42ef8b46f01e4ddd9fa626bab60d41f6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 100,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 100,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7cbe2450efea47de99dac82149b49e88"
          }
        },
        "fe9e2d8094e9467eaf79f186e18eb207": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3cfcf9106bd9401e93766c33b51d05e6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 100/100 [00:50&lt;00:00,  1.41it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1a3871a9dfc44ab498169c85b1a48a7c"
          }
        },
        "1a9e930b35654998a83d1bba6b319f44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e36e409e43f14b28ab702d6d8db6fac0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "42ef8b46f01e4ddd9fa626bab60d41f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7cbe2450efea47de99dac82149b49e88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3cfcf9106bd9401e93766c33b51d05e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1a3871a9dfc44ab498169c85b1a48a7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import the Music Transformer Model"
      ],
      "metadata": {
        "id": "TQBVgEa-aPQp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!pip install tensorflow-gpu\r\n",
        "!pip install -r requirements.txt \r\n",
        "!pip install tfp-nightly"
      ],
      "outputs": [],
      "metadata": {
        "id": "gpQ_IreEaTRR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from processor import encode_midi\r\n",
        "from processor import decode_midi\r\n",
        "from tensorflow.python import keras \r\n",
        "import utils\r\n",
        "import os\r\n",
        "import numpy as np\r\n",
        "import pandas as pd"
      ],
      "outputs": [],
      "metadata": {
        "id": "8VdGprP7bbJM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from model import MusicTransformerDecoder\r\n",
        "from custom.layers import *\r\n",
        "from custom import callback\r\n",
        "import params as par\r\n",
        "from tensorflow.python.keras.optimizer_v2.adam import Adam\r\n",
        "from data import Data\r\n",
        "import utils\r\n",
        "import argparse\r\n",
        "import datetime\r\n",
        "import sys"
      ],
      "outputs": [],
      "metadata": {
        "id": "_EADD0mXbos0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Declare constants \r\n",
        "batch_size = 2\r\n",
        "pickle_dir = 'Donnees'\r\n",
        "max_seq = 2048\r\n",
        "epochs = 10\r\n",
        "is_reuse = False\r\n",
        "load_path = None\r\n",
        "save_path = \"result/trainedmodel_entrainement\"\r\n",
        "multi_gpu = False\r\n",
        "num_layer = 6 # 6 multihead attention layers. "
      ],
      "outputs": [],
      "metadata": {
        "id": "vieOSf0KbqQk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Model Learning rate\r\n",
        "l_r = None\r\n",
        "learning_rate = callback.CustomSchedule(par.embedding_dim) if l_r is None else l_r\r\n",
        "opt = Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)"
      ],
      "outputs": [],
      "metadata": {
        "id": "fDCx5aiabzlj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# define model\r\n",
        "mt = MusicTransformerDecoder(\r\n",
        "            embedding_dim=256,\r\n",
        "            vocab_size=par.vocab_size,\r\n",
        "            num_layer=6,\r\n",
        "            max_seq=max_seq,\r\n",
        "            dropout=0.2,\r\n",
        "            debug=False, loader_path=load_path)\r\n",
        "mt.compile(optimizer=opt, loss=callback.transformer_dist_train_loss)"
      ],
      "outputs": [],
      "metadata": {
        "id": "686D1Pl-b7lm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Define tensorboard writer (only for logs)\n",
        "current_time = datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
        "train_log_dir = 'logs/mt_decoder/'+current_time+'/train'\n",
        "eval_log_dir = 'logs/mt_decoder/'+current_time+'/eval'\n",
        "train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
        "eval_summary_writer = tf.summary.create_file_writer(eval_log_dir)"
      ],
      "outputs": [],
      "metadata": {
        "id": "yIlSYySnb_7W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Loads the model\n",
        "mt.load_config_file(save_path)\n",
        "mt.load_ckpt_file(save_path)\n",
        "\n",
        "mt.reset_metrics()"
      ],
      "outputs": [],
      "metadata": {
        "id": "exubxwHwcFmz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Important Functions"
      ],
      "metadata": {
        "id": "7kSTVVk6dokf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import json\n",
        "\n",
        "def get_data(file,choice='all',nans=True,remove_duos=False):\n",
        "  \"\"\"\n",
        "  Returns a dataframe from the original maestro dataset\n",
        "  Args:\n",
        "    file: dataset file path\n",
        "    choice: choice of the set of composers to return (check ./maestro-v3.0.0/composers.json)\n",
        "    nans: if false, will remove null values\n",
        "    remove_duos: if true, will remove pieces of music from a duo of composers\n",
        "\n",
        "  Returns:\n",
        "      Dataframe according the parameters\n",
        "\n",
        "  Raises:\n",
        "      ValueError: if the choice is not in the possible list of choices.\n",
        "  \"\"\"\n",
        "  data = pd.read_csv(file)\n",
        "  if not nans:\n",
        "    try:\n",
        "      data = data.dropna()\n",
        "    except:\n",
        "      data = data.dropna(axis=0, how='all')\n",
        "\n",
        "  if remove_duos:\n",
        "    data = data[~data.canonical_composer.str.contains(\"/\")]\n",
        "\n",
        "  if choice=='all':\n",
        "    return data\n",
        "\n",
        "  FILE = open(\"maestro-v3.0.0/composers.json\", \"r\").read()\n",
        "  C = json.loads(FILE)\n",
        "  C = C[\"everyComposer\"]\n",
        "\n",
        "  if choice in C.keys():\n",
        "    data = data[data['canonical_composer'].isin(C[choice])]\n",
        "  else:\n",
        "    print(\"Choice not recognized, please check './maestro-v3.0.0/composers.json'\")\n",
        "    raise ValueError\n",
        "\n",
        "  return data"
      ],
      "outputs": [],
      "metadata": {
        "id": "k9rpYmYwcLWC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def get_last_layers(k, tens):\n",
        "  \"\"\"\n",
        "  Returns the last k layers of the model\n",
        "  Args:\n",
        "  k: layer number from 1 to 6, 0 < k < 5\n",
        "  \"\"\"\n",
        "  return tens[k:]\n",
        "\n",
        "def mean_pooling(tens):\n",
        "  \"\"\"Averages the matrices of a layer\"\"\"\n",
        "  return np.mean(tens[0][0],axis=0)"
      ],
      "outputs": [],
      "metadata": {
        "id": "IVvu9y9wdrky"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def chunks(lst, n):\n",
        "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
        "    for i in range(0, len(lst), n):\n",
        "        yield lst[i:i + n]\n",
        "\n",
        "list(chunks([1,2,3,4,5,6,7,8,9],4))"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 2, 3, 4], [5, 6, 7, 8], [9]]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0aJYO6uSeT-F",
        "outputId": "5ed4a2b3-a088-40ff-cf43-f4c79672be79"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from ast import literal_eval\n",
        "\n",
        "def literal_encoded(data):\n",
        "  \"\"\"Parses a string into a python array\"\"\"\n",
        "  return data[\"encoded_sequence\"].apply(lambda seq: literal_eval(seq))\n",
        "\n",
        "def get_attention(sequence):\n",
        "  \"\"\"Computes the self attention from a sequence of tokens\"\"\"\n",
        "  last_layer = get_last_layers(5,np.array(mt.Decoder( np.array([sequence]), training=None, mask=None)[1])) # Get the attention of the last layer\n",
        "  return mean_pooling(last_layer).flatten() # Compute the mean pooling"
      ],
      "outputs": [],
      "metadata": {
        "id": "3Y-p1l-YedQw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "def get_model(X,y,random_state=42):\n",
        "  \"\"\"Initialize our Logistic Regression\"\"\"\n",
        "  return LogisticRegression(random_state=random_state).fit(X, y)"
      ],
      "outputs": [],
      "metadata": {
        "id": "iL5WCdLIe6LW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Composer classifcation using attention matrices"
      ],
      "metadata": {
        "id": "lmefY5uDfaQ_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "data = get_data(file='maestro-64-unique-titles.csv',choice='top10',nans=True,remove_duos=True)\n",
        "data.canonical_composer.value_counts()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Franz Schubert             41647\n",
              "Ludwig van Beethoven       41375\n",
              "Franz Liszt                39025\n",
              "Frédéric Chopin            33755\n",
              "Robert Schumann            25374\n",
              "Johann Sebastian Bach      15755\n",
              "Sergei Rachmaninoff        14273\n",
              "Claude Debussy             11216\n",
              "Wolfgang Amadeus Mozart     9896\n",
              "Joseph Haydn                7123\n",
              "Name: canonical_composer, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BshuPtekj7lY",
        "outputId": "023159b2-3dc6-477e-999e-b78c367f731c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def train_test(data,composer1,composer2,train_size,test_size,random_state=42):\n",
        "  \"\"\"\n",
        "  Create an evenly distributed train_test set with data\n",
        "  Args:\n",
        "    data: DataFrame object representing our Dataset\n",
        "    composer1: Name of the first composer\n",
        "    composer2: Name of the second composer\n",
        "    \n",
        "  \"\"\"\n",
        "  #Get every title for each composer\n",
        "  A = data[data['canonical_composer'].isin([composer1])]\n",
        "  B = data[data['canonical_composer'].isin([composer2])]\n",
        "  \n",
        "  #Train set\n",
        "  temp1 = A[A['split'].isin([\"train\"])].sample(n=train_size//2,random_state=random_state)\n",
        "  temp2 = B[B['split'].isin([\"train\"])].sample(n=train_size//2,random_state=random_state)\n",
        "\n",
        "  train = pd.concat([temp1,temp2],ignore_index=True)\n",
        "\n",
        "  #Test set\n",
        "  temp3 = A[A['split'].isin([\"test\"])].sample(n=test_size//2,random_state=random_state)\n",
        "  temp4 = B[B['split'].isin([\"test\"])].sample(n=test_size//2,random_state=random_state)\n",
        "\n",
        "  test = pd.concat([temp3, temp4], ignore_index=True)\n",
        "\n",
        "  return train, test"
      ],
      "outputs": [],
      "metadata": {
        "id": "G51mI_G0kV2P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from tqdm.notebook import tqdm\n",
        "\n",
        "def encode_attention(dataset,show_tqdm=True):\n",
        "  \"\"\"\n",
        "  Create a dataset with the attentio of a sequence with its composer\n",
        "  Args:\n",
        "    dataset: base Dataframe dataset\n",
        "    show_tqdm: if false, will not show the progress\n",
        "\n",
        "  Returns:\n",
        "    df: DataFrame corresponding to each music sequence attention with its composer\n",
        "  \"\"\"\n",
        "  dataset.reset_index(drop=True,inplace=True)\n",
        "  X = []\n",
        "  y = []\n",
        "  PATH = \"\" # Set initial path\n",
        "  for ind in tqdm(dataset.index,leave=show_tqdm):\n",
        "      try:\n",
        "          new_PATH = \"maestro-v3.0.0/\"+dataset[\"midi_filename\"].iloc[ind]\n",
        "          if new_PATH != PATH:\n",
        "              # If we found a new path this means we have switch to another piece of music so we recompute the encoded sequence\n",
        "              PATH = new_PATH\n",
        "              encoded = encode_midi(PATH)\n",
        "      \n",
        "          start = dataset[\"start_ind\"].iloc[ind]\n",
        "          end = dataset[\"end_ind\"].iloc[ind]\n",
        "          attention = get_attention(encoded[start:end])\n",
        "      \n",
        "          X.append(attention)\n",
        "          y.append(dataset[\"canonical_composer\"].iloc[ind])\n",
        "      except:\n",
        "          print(\"Unexpected error:\", sys.exc_info()[0],\"Index:\",ind)\n",
        "          pass\n",
        "\n",
        "  df = pd.DataFrame(data=X)\n",
        "  df[\"canonical_composer\"] = y\n",
        "  return df"
      ],
      "outputs": [],
      "metadata": {
        "id": "r0jm_zcO7Ro3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "TESTS = {\n",
        "    \"H-M\":[\"Joseph Haydn\",\"Wolfgang Amadeus Mozart\"],\n",
        "    \"M-D\":[\"Wolfgang Amadeus Mozart\",\"Claude Debussy\"],\n",
        "    \"C-S\":[\"Frédéric Chopin\",\"Franz Schubert\"],\n",
        "    \"C-B\":[\"Frédéric Chopin\",\"Johann Sebastian Bach\"],\n",
        "    \"C-D\":[\"Frédéric Chopin\",\"Claude Debussy\"]\n",
        "}"
      ],
      "outputs": [],
      "metadata": {
        "id": "3X_SSZWU9JuZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "h = TESTS[\"M-D\"]\n",
        "\n",
        "print(\"-----------------------------------\")\n",
        "print(\"Processing...\",h)\n",
        "print(\"-----------------------------------\")\n",
        "\n",
        "res = [] # Array that will contain our scores\n",
        "TRAIN_SIZE = 100\n",
        "TEST_SIZE = 100\n",
        "nb_seeds = 1\n",
        "\n",
        "# Here we can switch the file to 'maestro-XX-unique-titles.csv' with XX corresponding to the sequence size (from 32, 64, 96 or 128)\n",
        "data = get_data(file='maestro-32-unique-titles.csv',choice='top10',nans=True,remove_duos=True)\n",
        "\n",
        "for seed in range(nb_seeds):\n",
        "\n",
        "    train, test = train_test(data,h[0],h[1],TRAIN_SIZE,TEST_SIZE,random_state=seed)\n",
        "\n",
        "    train_attention = encode_attention(train)\n",
        "    test_attention = encode_attention(test)\n",
        "\n",
        "    X_train, y_train = train_attention.loc[:, train_attention.columns != 'canonical_composer'], train_attention['canonical_composer']\n",
        "    X_test, y_test = test_attention.loc[:, test_attention.columns != 'canonical_composer'], test_attention['canonical_composer']\n",
        "\n",
        "    cls = get_model(X_train,y_train)\n",
        "\n",
        "    print(\"Seed :\",seed,\"Score :\",cls.score(X_test,y_test))\n",
        "    res.append(cls.score(X_test,y_test))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------\n",
            "Processing... ['Wolfgang Amadeus Mozart', 'Claude Debussy']\n",
            "-----------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a2ff3ef3a12340feb060fd2e535d150c",
              "version_minor": 0,
              "version_major": 2
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0e663659e57242aa8bea479addd72171",
              "version_minor": 0,
              "version_major": 2
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed : 0 Score : 0.57\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 149,
          "referenced_widgets": [
            "a2ff3ef3a12340feb060fd2e535d150c",
            "fe02979831c849148167a39c8ca5df03",
            "a9b9a0c46d5842bbae3bc30f2eddf1bb",
            "01aedd15071a4af49c0bb3813c24dc7c",
            "862324f1b1b84901973ffef866faabc8",
            "3e1817a32a22467e8a50b7ccfb9bb7c6",
            "ef04b5edb2584b81858e32a292203dda",
            "71a8fe9c180e4d0f9c31f9eff8b77da3",
            "1097bfdedc1148358a9f0d800f9376b4",
            "69498d87934d49a9864dfbee2f00d385",
            "b45ca13467cb410a8c80e0e693614a99",
            "0e663659e57242aa8bea479addd72171",
            "66d94737180d4b60939a5b5e47eee177",
            "5379065c672f49fdbb0c3ebb76ab69fc",
            "93b5202556554c8f88c2d3852df634f0",
            "fe9e2d8094e9467eaf79f186e18eb207",
            "1a9e930b35654998a83d1bba6b319f44",
            "e36e409e43f14b28ab702d6d8db6fac0",
            "42ef8b46f01e4ddd9fa626bab60d41f6",
            "7cbe2450efea47de99dac82149b49e88",
            "3cfcf9106bd9401e93766c33b51d05e6",
            "1a3871a9dfc44ab498169c85b1a48a7c"
          ]
        },
        "id": "N60uwRbY9h53",
        "outputId": "287f509c-b501-4fb5-c78b-fd3cc309c46f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cadence detection using attention matrices"
      ],
      "metadata": {
        "id": "naYUgEdGfdFm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!pip uninstall pandas;\n",
        "!pip install pretty-midi;\n",
        "!pip install pandas==1.1.0;\n",
        "%cd /content/gdrive/My Drive/Stage/CodeMusicTransformer"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: pandas 0.25.0\n",
            "Uninstalling pandas-0.25.0:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.7/dist-packages/pandas-0.25.0.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/pandas/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled pandas-0.25.0\n",
            "Requirement already satisfied: pretty-midi in /usr/local/lib/python3.7/dist-packages (0.2.8)\n",
            "Requirement already satisfied: mido>=1.1.16 in /usr/local/lib/python3.7/dist-packages (from pretty-midi) (1.2.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from pretty-midi) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from pretty-midi) (1.21.2)\n",
            "Collecting pandas==1.1.0\n",
            "  Downloading pandas-1.1.0-cp37-cp37m-manylinux1_x86_64.whl (10.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.5 MB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas==1.1.0) (1.21.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.1.0) (2.8.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas==1.1.0) (2019.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas==1.1.0) (1.12.0)\n",
            "Installing collected packages: pandas\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires astor~=0.8.1, but you have astor 0.8.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.22.0 which is incompatible.\n",
            "google-colab 1.0.0 requires six~=1.15.0, but you have six 1.12.0 which is incompatible.\u001b[0m\n",
            "Successfully installed pandas-1.1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pandas"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/My Drive/Stage/CodeMusicTransformer\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "id": "SCfv2PWgfiL0",
        "outputId": "07cb368c-6ee7-411c-dbfc-7c25ad5333e8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "\"\"\"\n",
        "In order to make our model work with cadence folder we have to make small changes to our encoding function\n",
        "\"\"\"\n",
        "import pretty_midi\n",
        "\n",
        "\n",
        "RANGE_NOTE_ON = 128\n",
        "RANGE_NOTE_OFF = 128\n",
        "RANGE_VEL = 32\n",
        "RANGE_TIME_SHIFT = 100\n",
        "\n",
        "START_IDX = {\n",
        "    'note_on': 0,\n",
        "    'note_off': RANGE_NOTE_ON,\n",
        "    'time_shift': RANGE_NOTE_ON + RANGE_NOTE_OFF,\n",
        "    'velocity': RANGE_NOTE_ON + RANGE_NOTE_OFF + RANGE_TIME_SHIFT\n",
        "}\n",
        "\n",
        "\n",
        "class SustainAdapter:\n",
        "    def __init__(self, time, type):\n",
        "        self.start =  time\n",
        "        self.type = type\n",
        "\n",
        "\n",
        "class SustainDownManager:\n",
        "    def __init__(self, start, end):\n",
        "        self.start = start\n",
        "        self.end = end\n",
        "        self.managed_notes = []\n",
        "        self._note_dict = {} # key: pitch, value: note.start\n",
        "\n",
        "    def add_managed_note(self, note: pretty_midi.Note):\n",
        "        self.managed_notes.append(note)\n",
        "\n",
        "    def transposition_notes(self):\n",
        "        for note in reversed(self.managed_notes):\n",
        "            try:\n",
        "                note.end = self._note_dict[note.pitch]\n",
        "            except KeyError:\n",
        "                note.end = max(self.end, note.end)\n",
        "            self._note_dict[note.pitch] = note.start\n",
        "\n",
        "\n",
        "# Divided note by note_on, note_off\n",
        "class SplitNote:\n",
        "    def __init__(self, type, time, value, velocity):\n",
        "        ## type: note_on, note_off\n",
        "        self.type = type\n",
        "        self.time = time\n",
        "        self.velocity = velocity\n",
        "        self.value = value\n",
        "\n",
        "    def __repr__(self):\n",
        "        return '<[SNote] time: {} type: {}, value: {}, velocity: {}>'\\\n",
        "            .format(self.time, self.type, self.value, self.velocity)\n",
        "\n",
        "\n",
        "class Event:\n",
        "    def __init__(self, event_type, value):\n",
        "        self.type = event_type\n",
        "        self.value = value\n",
        "\n",
        "    def __repr__(self):\n",
        "        return '<Event type: {}, value: {}>'.format(self.type, self.value)\n",
        "\n",
        "    def to_int(self):\n",
        "        return START_IDX[self.type] + self.value\n",
        "\n",
        "    @staticmethod\n",
        "    def from_int(int_value):\n",
        "        info = Event._type_check(int_value)\n",
        "        return Event(info['type'], info['value'])\n",
        "\n",
        "    @staticmethod\n",
        "    def _type_check(int_value):\n",
        "        range_note_on = range(0, RANGE_NOTE_ON)\n",
        "        range_note_off = range(RANGE_NOTE_ON, RANGE_NOTE_ON+RANGE_NOTE_OFF)\n",
        "        range_time_shift = range(RANGE_NOTE_ON+RANGE_NOTE_OFF,RANGE_NOTE_ON+RANGE_NOTE_OFF+RANGE_TIME_SHIFT)\n",
        "\n",
        "        valid_value = int_value\n",
        "\n",
        "        if int_value in range_note_on:\n",
        "            return {'type': 'note_on', 'value': valid_value}\n",
        "        elif int_value in range_note_off:\n",
        "            valid_value -= RANGE_NOTE_ON\n",
        "            return {'type': 'note_off', 'value': valid_value}\n",
        "        elif int_value in range_time_shift:\n",
        "            valid_value -= (RANGE_NOTE_ON + RANGE_NOTE_OFF)\n",
        "            return {'type': 'time_shift', 'value': valid_value}\n",
        "        else:\n",
        "            valid_value -= (RANGE_NOTE_ON + RANGE_NOTE_OFF + RANGE_TIME_SHIFT)\n",
        "            return {'type': 'velocity', 'value': valid_value}\n",
        "\n",
        "\n",
        "def _divide_note(notes):\n",
        "    result_array = []\n",
        "    notes.sort(key=lambda x: x.start)\n",
        "\n",
        "    for note in notes:\n",
        "        on = SplitNote('note_on', note.start, note.pitch, note.velocity)\n",
        "        off = SplitNote('note_off', note.end, note.pitch, None)\n",
        "        result_array += [on, off]\n",
        "    return result_array\n",
        "\n",
        "\n",
        "def _merge_note(snote_sequence):\n",
        "    note_on_dict = {}\n",
        "    result_array = []\n",
        "\n",
        "    for snote in snote_sequence:\n",
        "        # print(note_on_dict)\n",
        "        if snote.type == 'note_on':\n",
        "            note_on_dict[snote.value] = snote\n",
        "        elif snote.type == 'note_off':\n",
        "            try:\n",
        "                on = note_on_dict[snote.value]\n",
        "                off = snote\n",
        "                if off.time - on.time == 0:\n",
        "                    continue\n",
        "                result = pretty_midi.Note(on.velocity, snote.value, on.time, off.time)\n",
        "                result_array.append(result)\n",
        "            except:\n",
        "                print('info removed pitch: {}'.format(snote.value))\n",
        "    return result_array\n",
        "\n",
        "\n",
        "def _snote2events(snote: SplitNote, prev_vel: int):\n",
        "    result = []\n",
        "    if snote.velocity is not None:\n",
        "        modified_velocity = snote.velocity // 4\n",
        "        if prev_vel != modified_velocity:\n",
        "            result.append(Event(event_type='velocity', value=modified_velocity))\n",
        "    result.append(Event(event_type=snote.type, value=snote.value))\n",
        "    return result\n",
        "\n",
        "\n",
        "def _event_seq2snote_seq(event_sequence):\n",
        "    timeline = 0\n",
        "    velocity = 0\n",
        "    snote_seq = []\n",
        "\n",
        "    for event in event_sequence:\n",
        "        if event.type == 'time_shift':\n",
        "            timeline += ((event.value+1) / 100)\n",
        "        if event.type == 'velocity':\n",
        "            velocity = event.value * 4\n",
        "        else:\n",
        "            snote = SplitNote(event.type, timeline, event.value, velocity)\n",
        "            snote_seq.append(snote)\n",
        "    return snote_seq\n",
        "\n",
        "\n",
        "def _make_time_sift_events(prev_time, post_time):\n",
        "    time_interval = int(round((post_time - prev_time) * 100))\n",
        "    results = []\n",
        "    while time_interval >= RANGE_TIME_SHIFT:\n",
        "        results.append(Event(event_type='time_shift', value=RANGE_TIME_SHIFT-1))\n",
        "        time_interval -= RANGE_TIME_SHIFT\n",
        "    if time_interval == 0:\n",
        "        return results\n",
        "    else:\n",
        "        return results + [Event(event_type='time_shift', value=time_interval-1)]\n",
        "\n",
        "\n",
        "def _control_preprocess(ctrl_changes):\n",
        "    sustains = []\n",
        "\n",
        "    manager = None\n",
        "    for ctrl in ctrl_changes:\n",
        "        if ctrl.value >= 64 and manager is None:\n",
        "            # sustain down\n",
        "            manager = SustainDownManager(start=ctrl.time, end=None)\n",
        "        elif ctrl.value < 64 and manager is not None:\n",
        "            # sustain up\n",
        "            manager.end = ctrl.time\n",
        "            sustains.append(manager)\n",
        "            manager = None\n",
        "        elif ctrl.value < 64 and len(sustains) > 0:\n",
        "            sustains[-1].end = ctrl.time\n",
        "    return sustains\n",
        "\n",
        "\n",
        "def _note_preprocess(susteins, notes):\n",
        "    note_stream = []\n",
        "\n",
        "    for sustain in susteins:\n",
        "        for note_idx, note in enumerate(notes):\n",
        "            if note.start < sustain.start:\n",
        "                note_stream.append(note)\n",
        "            elif note.start > sustain.end:\n",
        "                notes = notes[note_idx:]\n",
        "                sustain.transposition_notes()\n",
        "                break\n",
        "            else:\n",
        "                sustain.add_managed_note(note)\n",
        "\n",
        "    for sustain in susteins:\n",
        "        note_stream += sustain.managed_notes\n",
        "\n",
        "    note_stream.sort(key= lambda x: x.start)\n",
        "    return note_stream\n",
        "\n",
        "def _note_preprocess2(notes):\n",
        "    note_stream = []\n",
        "\n",
        "    for note in notes:\n",
        "      note_stream.append(note)\n",
        "\n",
        "    note_stream.sort(key= lambda x: x.start)\n",
        "    return note_stream\n",
        "\n",
        "\n",
        "def encode_midi_no_sustain(file_path, get_times=False):\n",
        "    # Only for time comparison with Transformer\n",
        "    real_times = []\n",
        "    approx_times = []\n",
        "    ############################################\n",
        "\n",
        "    events = []\n",
        "    notes = []\n",
        "    mid = pretty_midi.PrettyMIDI(midi_file=file_path)\n",
        "\n",
        "    for inst in mid.instruments:\n",
        "        inst_notes = inst.notes\n",
        "        # ctrl.number is the number of sustain control. If you want to know abour the number type of control,\n",
        "        # see https://www.midi.org/specifications-old/item/table-3-control-change-messages-data-bytes-2\n",
        "        # ctrls = _control_preprocess([ctrl for ctrl in inst.control_changes if ctrl.number == 64])\n",
        "        notes += _note_preprocess2(inst_notes)\n",
        "\n",
        "    dnotes = _divide_note(notes)\n",
        "\n",
        "    #print(dnotes)\n",
        "    dnotes.sort(key=lambda x: x.time)\n",
        "    #print('sorted:')\n",
        "    #print(dnotes)\n",
        "    cur_time = 0\n",
        "    cur_vel = 0\n",
        "\n",
        "    # transformer\n",
        "    sift = 0\n",
        "    for snote in dnotes:\n",
        "        #Make dictionnary with id, real_time, apprx_time\n",
        "        real_times.append(snote.time*1000)# in milliseconds\n",
        "        #print(snote.time)\n",
        "        time_sift_container = _make_time_sift_events(prev_time=cur_time, post_time=snote.time)\n",
        "\n",
        "        for event in time_sift_container:\n",
        "          sift += event.value + 1\n",
        "        approx_times.append(sift*10)# There is no 0\n",
        "\n",
        "        events += _make_time_sift_events(prev_time=cur_time, post_time=snote.time)\n",
        "        events += _snote2events(snote=snote, prev_vel=cur_vel)\n",
        "        # events += _make_time_sift_events(prev_time=cur_time, post_time=snote.time)\n",
        "\n",
        "        cur_time = snote.time\n",
        "        cur_vel = snote.velocity\n",
        "\n",
        "    if get_times:\n",
        "      return [e.to_int() for e in events], real_times, approx_times\n",
        "    else:\n",
        "      return [e.to_int() for e in events]\n",
        "\n",
        "\n",
        "def decode_midi(idx_array, file_path=None):\n",
        "    event_sequence = [Event.from_int(idx) for idx in idx_array]\n",
        "    # print(event_sequence)\n",
        "    snote_seq = _event_seq2snote_seq(event_sequence)\n",
        "    note_seq = _merge_note(snote_seq)\n",
        "    note_seq.sort(key=lambda x:x.start)\n",
        "\n",
        "    mid = pretty_midi.PrettyMIDI()\n",
        "    # if want to change instument, see https://www.midi.org/specifications/item/gm-level-1-sound-set\n",
        "    instument = pretty_midi.Instrument(1, False, \"Developed By Yang-Kichang\")\n",
        "    instument.notes = note_seq\n",
        "\n",
        "    mid.instruments.append(instument)\n",
        "    if file_path is not None:\n",
        "        mid.write(file_path)\n",
        "    return mid"
      ],
      "outputs": [],
      "metadata": {
        "id": "n2UjuqST-3sp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "PATH = 'Cadences/midi_files/wtc-i-04.mid'\n",
        "encoded, A, B = encode_midi_no_sustain(PATH,True)\n",
        "len(encoded)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4698"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ff2fhUAR_fSU",
        "outputId": "57575011-36b7-4da8-f0db-b437fff460b3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "midi_data = pretty_midi.PrettyMIDI(PATH)\n",
        "\n",
        "def offset_to_real_time(midi_data,offset):\n",
        "    tempo_changes = midi_data.get_tempo_changes()\n",
        "    bpm = tempo_changes[1][0]\n",
        "    beat_duration_ms = 1000*60/bpm\n",
        "    return offset * beat_duration_ms\n",
        "\n",
        "for i in range(9):\n",
        "    print('offset {} : {}'.format(i,offset_to_real_time(midi_data,i)))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "offset 0 : 0.0\n",
            "offset 1 : 560.748\n",
            "offset 2 : 1121.496\n",
            "offset 3 : 1682.2440000000001\n",
            "offset 4 : 2242.992\n",
            "offset 5 : 2803.7400000000002\n",
            "offset 6 : 3364.4880000000003\n",
            "offset 7 : 3925.2360000000003\n",
            "offset 8 : 4485.984\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tArx5ufL_Zz9",
        "outputId": "0b035fd4-e6cc-4c0a-d02f-014319cb092d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "temp = encoded[:30] \n",
        "time = 0\n",
        "print(\"Event || Time\")\n",
        "for event in temp:\n",
        "  infos = \"\"\n",
        "  if 256 <= event <= 355 :\n",
        "    time += (event-255)*10\n",
        "\n",
        "  if 0 <= event <= 127:\n",
        "    infos += \"<- Note_On, Pitch = \"+str(event)\n",
        "\n",
        "  if 128 <= event <= 255:\n",
        "    infos += \"<- Note_Off, Pitch = \"+str(event - 128)\n",
        "\n",
        "  if 356 <= event <= 387:\n",
        "    infos += \"<- VelocityEvent, Volume de la note = \"+str(event - 355)\n",
        "  print(event,\"||\",time,infos)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Event || Time\n",
            "378 || 0 <- VelocityEvent, Volume de la note = 23\n",
            "49 || 0 <- Note_On, Pitch = 49\n",
            "355 || 1000 \n",
            "355 || 2000 \n",
            "279 || 2240 \n",
            "177 || 2240 <- Note_Off, Pitch = 49\n",
            "378 || 2240 <- VelocityEvent, Volume de la note = 23\n",
            "48 || 2240 <- Note_On, Pitch = 48\n",
            "355 || 3240 \n",
            "267 || 3360 \n",
            "176 || 3360 <- Note_Off, Pitch = 48\n",
            "378 || 3360 <- VelocityEvent, Volume de la note = 23\n",
            "52 || 3360 <- Note_On, Pitch = 52\n",
            "355 || 4360 \n",
            "267 || 4480 \n",
            "180 || 4480 <- Note_Off, Pitch = 52\n",
            "378 || 4480 <- VelocityEvent, Volume de la note = 23\n",
            "51 || 4480 <- Note_On, Pitch = 51\n",
            "355 || 5480 \n",
            "355 || 6480 \n",
            "279 || 6720 \n",
            "179 || 6720 <- Note_Off, Pitch = 51\n",
            "378 || 6720 <- VelocityEvent, Volume de la note = 23\n",
            "56 || 6720 <- Note_On, Pitch = 56\n",
            "378 || 6720 <- VelocityEvent, Volume de la note = 23\n",
            "49 || 6720 <- Note_On, Pitch = 49\n",
            "311 || 7280 \n",
            "177 || 7280 <- Note_Off, Pitch = 49\n",
            "378 || 7280 <- VelocityEvent, Volume de la note = 23\n",
            "51 || 7280 <- Note_On, Pitch = 51\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BJ2eT0dADhS",
        "outputId": "24984e01-174b-4ff7-b3b3-572824a1ae2b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def get_start_end_sequence(sequence,time):\n",
        "  \"\"\"\n",
        "  Get the first starting / ending index of a token in a sequence\n",
        "  Args:\n",
        "    sequence: the sequence of integers\n",
        "    time: token \n",
        "  \"\"\"\n",
        "  start = -1\n",
        "  end = -1\n",
        "  temp = False\n",
        "  for i in range(len(sequence)):\n",
        "    if sequence[i] == time and not temp: #Entering \n",
        "      start = i\n",
        "      temp = True\n",
        "    elif (sequence[i] != time or i == len(sequence)-1) and temp: #leaving\n",
        "      end = i\n",
        "      return start,end\n",
        "    else:\n",
        "      pass\n",
        "  return 0,0\n",
        "\n",
        "get_start_end_sequence([0,0,0,1,1,1,2,2,2,2,1,1,1,1,2,2,2],2)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yw4sskKYANue",
        "outputId": "887e39ca-f966-4f19-a22c-bb5cc2475c98"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def get_cadences_sequences(midi_file,csv_file,size, offsets_X_Y=False):\n",
        "  \"\"\"\n",
        "  Generate from a midi_file and a csv_file a dataset with sequences of size size well labeled for cadence detection\n",
        "\n",
        "  offsets_X_Y will display the indexes of offsets X and Y in the sequence\n",
        "  \"\"\"\n",
        "  offsets = []\n",
        "\n",
        "  offsets_bis = []\n",
        "\n",
        "  cadences_file = pd.read_csv(csv_file)\n",
        "  midi_data = pretty_midi.PrettyMIDI(midi_file)\n",
        "\n",
        "  for offset in cadences_file.loc[cadences_file['PAC (truth)'] == True][\"offset Z\"]:\n",
        "    # for each offset int the file, we will keep its real time in the offsets array and its offset time in the offsets_bis array\n",
        "    offsets.append(offset_to_real_time(midi_data,offset))\n",
        "    offsets_bis.append(offset)\n",
        "\n",
        "  \"\"\" Display X_Y\"\"\"\n",
        "  offsets_X = []\n",
        "  offsets_Y = []  \n",
        "\n",
        "  for offset in cadences_file.loc[cadences_file['PAC (truth)'] == True][\"offset X\"]:\n",
        "    offsets_X.append(offset_to_real_time(midi_data,offset))\n",
        "\n",
        "  for offset in cadences_file.loc[cadences_file['PAC (truth)'] == True][\"offset Y\"]:\n",
        "    offsets_Y.append(offset_to_real_time(midi_data,offset))\n",
        "  \n",
        "  \"\"\"\"\"\"\n",
        "\n",
        "\n",
        "  start_ind = []\n",
        "  end_ind = []\n",
        "  contains_cadence = []\n",
        "  \"\"\"\"\"\"\n",
        "  offset_if_cadence = []\n",
        "\n",
        "  X_start = []\n",
        "  X_end = []\n",
        "  Y_start = []\n",
        "  Y_end = []\n",
        "  Z_start = []\n",
        "  Z_end = []\n",
        "  \"\"\"\"\"\"\n",
        "\n",
        "  encoded, real_time, approx_time = encode_midi_no_sustain(midi_file,True)\n",
        "\n",
        "  ###\n",
        "  real_time = [round(i) for i in real_time]\n",
        "  ###\n",
        "  \"\"\"\"\"\"\n",
        "  time = 0\n",
        "  times = []\n",
        "  for event in encoded:\n",
        "    if 256 <= event <= 355 :\n",
        "      time += (event-255)*10\n",
        "    times.append(time)\n",
        "  \"\"\"\"\"\"\n",
        "  #print(\"Time from sequence\")\n",
        "  #print(times)\n",
        "  #print(\"Approx Time\")\n",
        "  #print(approx_time)\n",
        "  #print(\"Real Time\")\n",
        "  #print(real_time)\n",
        "  i_start = 0\n",
        "  i_end = size\n",
        "  while i_end < len(encoded):\n",
        "    start_ind.append(i_start)\n",
        "    end_ind.append(i_end)\n",
        "\n",
        "    contains_cadence.append(False)\n",
        "    offset_if_cadence.append(None)\n",
        "\n",
        "    if offsets_X_Y:\n",
        "      X_start.append(None)\n",
        "      X_end.append(None)\n",
        "      Y_start.append(None)\n",
        "      Y_end.append(None)\n",
        "      Z_start.append(None)\n",
        "      Z_end.append(None)\n",
        "\n",
        "    for i,off in enumerate(offsets):\n",
        "      index = real_time.index(round(off))\n",
        "\n",
        "      \"\"\"\"\"\"\n",
        "      if offsets_X_Y:\n",
        "        index_X = real_time.index(round(offsets_X[i]))\n",
        "        index_Y = real_time.index(round(offsets_Y[i]))\n",
        "      \"\"\"\"\"\"\n",
        "      #print(i_end, times)\n",
        "      if times[i_start] < approx_time[index] < times[i_end]:\n",
        "        #Here we only keep sequences if its cadence is at least after halt of the sequence\n",
        "        if (times[i_start]+times[i_end])/2 <= approx_time[index] <= times[i_end]:\n",
        "          contains_cadence[-1] = True\n",
        "          offset_if_cadence[-1] = offsets_bis[offsets.index(off)]\n",
        "          if offsets_X_Y:\n",
        "            X = get_start_end_sequence(times, approx_time[index_X])\n",
        "            X_start[-1] = int(X[0])\n",
        "            X_end[-1] = int(X[1])\n",
        "\n",
        "            Y = get_start_end_sequence(times, approx_time[index_Y])\n",
        "            Y_start[-1] = int(Y[0])\n",
        "            Y_end[-1] = int(Y[1])\n",
        "\n",
        "            Z = get_start_end_sequence(times, approx_time[index])\n",
        "            Z_start[-1] = int(Z[0])\n",
        "            Z_end[-1] = int(Z[1])\n",
        "\n",
        "        else:\n",
        "          start_ind.pop()\n",
        "          end_ind.pop()\n",
        "          contains_cadence.pop()\n",
        "          offset_if_cadence.pop()\n",
        "\n",
        "          if offsets_X_Y:\n",
        "            X_start.pop()\n",
        "            X_end.pop()\n",
        "            Y_start.pop()\n",
        "            Y_end.pop()\n",
        "            Z_start.pop()\n",
        "            Z_end.pop()\n",
        "\n",
        "\n",
        "    i_start += 1\n",
        "    i_end += 1\n",
        "# Export all the data in a dataframe\n",
        "  df = pd.DataFrame()\n",
        "  df[\"start_ind\"] = start_ind\n",
        "  df[\"end_ind\"] = end_ind\n",
        "  df[\"contains_cadence\"] = contains_cadence\n",
        "  df[\"offset_if_cadence\"] = offset_if_cadence\n",
        "  if offsets_X_Y:\n",
        "    df[\"X_start\"] = X_start\n",
        "    df[\"X_end\"] = X_end\n",
        "    df[\"Y_start\"] = Y_start\n",
        "    df[\"Y_end\"] = Y_end\n",
        "    df[\"Z_start\"] = Z_start\n",
        "    df[\"Z_end\"] = Z_end\n",
        "\n",
        "  return df"
      ],
      "outputs": [],
      "metadata": {
        "id": "xQINeTPwAuXR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "id = \"01\"\n",
        "A = get_cadences_sequences(\"Cadences/midi_files/wtc-i-\"+id+\".mid\",\"Cadences/csv_files/wtc-i-\"+id+\".csv\",64,offsets_X_Y=True)\n",
        "#A.offset_if_cadence.value_counts()\n",
        "A\n",
        "A.loc[A['contains_cadence'] == True].head(3)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      start_ind  end_ind  contains_cadence  ...   Y_end  Z_start   Z_end\n",
              "1157       1157     1221              True  ...  1207.0   1211.0  1221.0\n",
              "1158       1158     1222              True  ...  1207.0   1211.0  1221.0\n",
              "1159       1159     1223              True  ...  1207.0   1211.0  1221.0\n",
              "\n",
              "[3 rows x 10 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>start_ind</th>\n",
              "      <th>end_ind</th>\n",
              "      <th>contains_cadence</th>\n",
              "      <th>offset_if_cadence</th>\n",
              "      <th>X_start</th>\n",
              "      <th>X_end</th>\n",
              "      <th>Y_start</th>\n",
              "      <th>Y_end</th>\n",
              "      <th>Z_start</th>\n",
              "      <th>Z_end</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1157</th>\n",
              "      <td>1157</td>\n",
              "      <td>1221</td>\n",
              "      <td>True</td>\n",
              "      <td>52.0</td>\n",
              "      <td>1168.0</td>\n",
              "      <td>1178.0</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>1207.0</td>\n",
              "      <td>1211.0</td>\n",
              "      <td>1221.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1158</th>\n",
              "      <td>1158</td>\n",
              "      <td>1222</td>\n",
              "      <td>True</td>\n",
              "      <td>52.0</td>\n",
              "      <td>1168.0</td>\n",
              "      <td>1178.0</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>1207.0</td>\n",
              "      <td>1211.0</td>\n",
              "      <td>1221.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1159</th>\n",
              "      <td>1159</td>\n",
              "      <td>1223</td>\n",
              "      <td>True</td>\n",
              "      <td>52.0</td>\n",
              "      <td>1168.0</td>\n",
              "      <td>1178.0</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>1207.0</td>\n",
              "      <td>1211.0</td>\n",
              "      <td>1221.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "CAEm4qAxB2gR",
        "outputId": "52d7643c-f001-4c64-8852-9349dc88729c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def downsample(df):\n",
        "  \"\"\"\n",
        "  Downsample a dataframe so the underrepresented class represent 33% of the total dataset\n",
        "  \"\"\"\n",
        "\n",
        "  cadences = df.loc[df['contains_cadence'] == True]\n",
        "  not_cadences = df.loc[df['contains_cadence'] == False]\n",
        "\n",
        "  nmin = df['contains_cadence'].value_counts().min()\n",
        "\n",
        "  undersample = not_cadences.sample(2*nmin,random_state=42)\n",
        "\n",
        "  return pd.concat([undersample,cadences]).reset_index(drop=True)\n",
        "\n",
        "id = \"01\"\n",
        "A = get_cadences_sequences(\"Cadences/midi_files/wtc-i-\"+id+\".mid\",\"Cadences/csv_files/wtc-i-\"+id+\".csv\",64)\n",
        "print(A.contains_cadence.value_counts())\n",
        "print(\"---Downsampling---\") \n",
        "print(downsample(A).contains_cadence.value_counts())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False    2378\n",
            "True       66\n",
            "Name: contains_cadence, dtype: int64\n",
            "---Downsampling---\n",
            "False    132\n",
            "True      66\n",
            "Name: contains_cadence, dtype: int64\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ih-rm7rhDgEX",
        "outputId": "f72d65cc-fc1d-4379-e1c0-a42a5cecbd54"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from tqdm.notebook import tqdm\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "outputs": [],
      "metadata": {
        "id": "ynLfLUNwD2UJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "file_numbers = [\"0\"+str(i) if i<10 else str(i) for i in range(1,25)]\n",
        "scores = []\n",
        "scores2 = []\n",
        "M_scores = np.zeros((2,2))\n",
        "D_scores = np.zeros((2,2))\n",
        "\n",
        "try:\n",
        "  # Remove files that does not contain any candence\n",
        "  file_numbers.remove(\"10\")\n",
        "  file_numbers.remove(\"12\")\n",
        "  file_numbers.remove(\"20\")\n",
        "  file_numbers.remove(\"24\")\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "PATH = \"Cadences/midi_files/wtc-i-03.mid\"\n",
        "train_set = pd.DataFrame()\n",
        "test_set = pd.DataFrame()\n",
        "\n",
        "for train_index, test_index in tqdm(LeaveOneOut().split(file_numbers)):\n",
        "  train_set = pd.DataFrame()\n",
        "  test_set = pd.DataFrame()\n",
        "  for i in train_index:\n",
        "    temp = get_cadences_sequences(\"Cadences/midi_files/wtc-i-\"+file_numbers[i]+\".mid\",\"Cadences/csv_files/wtc-i-\"+file_numbers[i]+\".csv\",64)\n",
        "    dataset = downsample(temp)\n",
        "    encoded = encode_midi_no_sustain(\"Cadences/midi_files/wtc-i-\"+file_numbers[i]+\".mid\")\n",
        "\n",
        "    X, y = [], []\n",
        "\n",
        "    for ind in dataset.index:\n",
        "      start = dataset[\"start_ind\"].iloc[ind]\n",
        "      end = dataset[\"end_ind\"].iloc[ind]\n",
        "      attention = get_attention(encoded[start:end])\n",
        "\n",
        "      X.append(attention)\n",
        "      y.append(dataset[\"contains_cadence\"].iloc[ind])\n",
        "\n",
        "    df = pd.DataFrame(data=X)\n",
        "    df[\"contains_cadence\"] = y\n",
        "\n",
        "    train_set = pd.concat([train_set,df],ignore_index=True)\n",
        "\n",
        "\n",
        "  for j in test_index:\n",
        "    temp = get_cadences_sequences(\"Cadences/midi_files/wtc-i-\"+file_numbers[j]+\".mid\",\"Cadences/csv_files/wtc-i-\"+file_numbers[j]+\".csv\",64)\n",
        "    dataset = downsample(temp)\n",
        "    encoded = encode_midi_no_sustain(\"Cadences/midi_files/wtc-i-\"+file_numbers[j]+\".mid\")\n",
        "      \n",
        "    X, y = [], []\n",
        "    for ind in dataset.index:\n",
        "      start = dataset[\"start_ind\"].iloc[ind]\n",
        "      end = dataset[\"end_ind\"].iloc[ind]\n",
        "      attention = get_attention(encoded[start:end])\n",
        "\n",
        "      X.append(attention)\n",
        "      y.append(dataset[\"contains_cadence\"].iloc[ind])\n",
        "\n",
        "    df = pd.DataFrame(data=X)\n",
        "    df[\"contains_cadence\"] = y\n",
        "     \n",
        "    test_set = pd.concat([test_set,df],ignore_index=True)\n",
        "\n",
        "  \n",
        "  #Encode train set\n",
        "\n",
        "\n",
        "  X_train, y_train = train_set.loc[:, train_set.columns != 'contains_cadence'], train_set['contains_cadence']\n",
        "  X_test, y_test = test_set.loc[:, test_set.columns != 'contains_cadence'], test_set['contains_cadence']\n",
        "\n",
        "  lr = LogisticRegression(solver=\"liblinear\").fit(X_train, y_train)\n",
        "  dummy = DummyClassifier(strategy=\"stratified\").fit(X_train, y_train)\n",
        "  y_pred = lr.predict(X_test)\n",
        "  y_dummy_pred = dummy.predict(X_test)\n",
        "\n",
        "  scores.append(f1_score(y_test,y_pred))\n",
        "  scores2.append(f1_score(y_test,y_dummy_pred))\n",
        "  M_scores += confusion_matrix(y_test,y_pred)\n",
        "  D_scores += confusion_matrix(y_test,y_dummy_pred)\n",
        "  print(\"F1 score =\",f1_score(y_test,y_pred),\"Dummy F1 score =\",f1_score(y_test,y_dummy_pred))"
      ],
      "outputs": [],
      "metadata": {
        "id": "LHBu6LLhD8sG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "M_scores"
      ],
      "outputs": [],
      "metadata": {
        "id": "hzLDNxTeuyuY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "D_scores"
      ],
      "outputs": [],
      "metadata": {
        "id": "lMxzCVmNuz_P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {
        "id": "qLPrF0IKu09f"
      }
    }
  ]
}